{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This tutorial shows how to load a Darknet dataset from yoloVx x > 4.\n",
    "For that we have defined a reader that wraps Ultralitics dataset format (different structured darknet format)\n",
    "https://github.com/ultralytics/ultralytics/issues/3087\n",
    "\"\"\"\n",
    "from deepview.datasets.readers import TFUltralyticsDetectionReader\n",
    "from deepview.datasets.iterators import TFObjectDetectionIterator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Different to previous dataset readers, this class does not expect the `annotations` parameter.\n",
    "The `images` parameter is a txt file that contains the relative/absolute path to images from a partition.\n",
    "\n",
    "To test this please clone yolov5 or yolov7, then download the coco dataset using their script and initialize the class instance.\n",
    "In this tutorial coco dataset was downloaded into the current directory `dataset/coco/`\n",
    "\n",
    "datasets\n",
    "└── coco\n",
    "    ├── annotations\n",
    "    │   └── instances_val2017.json\n",
    "    ├── images\n",
    "    │   ├── train2017\n",
    "    │   └── val2017\n",
    "    ├── labels\n",
    "    │   ├── train2017\n",
    "    │   └── val2017\n",
    "    ├── LICENSE\n",
    "    ├── README.txt\n",
    "    ├── test-dev2017.txt\n",
    "    ├── train2017.txt\n",
    "    └── val2017.txt\n",
    "\n",
    "To create the dataset reader instance, we just need to select tha annotations from the partition we want `train2017.txt`.\n",
    "The base path to the dataset is specified in parameter `path`. The reader will automatically convert all the paths as valid.\n",
    "\n",
    "This is a fragment of the annotation file:\n",
    "\n",
    "./images/train2017/000000109622.jpg\n",
    "./images/train2017/000000160694.jpg\n",
    "./images/train2017/000000308590.jpg\n",
    "\n",
    "Notice how the paths are relaive to the folder `coco`.\n",
    "\n",
    "Notice that Labels are passed as a yaml file, It also could be either of:\n",
    "- A txt file containing the names of the labels per row\n",
    "- A yaml file like described by ModelPack dataset formats (with a filed named `classes`)\n",
    "- A yaml file like the one used for YoloV5: https://github.com/ultralytics/yolov5/blob/master/data/coco.yaml\n",
    "- A yaml file like the one used for YoloV7: https://github.com/WongKinYiu/yolov7/blob/main/data/coco.yaml\n",
    "\n",
    "\"\"\"\n",
    "reader = TFUltralyticsDetectionReader(\n",
    "    images=\"train2017.txt\",\n",
    "    classes=\"yolov5/data/coco.yaml\",\n",
    "    path=\"datasets/coco\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The Iterator orchestrates the batching and augmentation techniques along the reader.\n",
    "\"\"\"\n",
    "handler = TFObjectDetectionIterator(\n",
    "    reader=reader,\n",
    "    shape=(320, 320, 3),\n",
    "    shuffle=True\n",
    ")\n",
    "iterator = handler.iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We can iterate along the iterator. Notice that batch is not defined, so elements won't be batched.\n",
    "\"\"\"\n",
    "for image, boxes in iterator:\n",
    "    print(image.shape, boxes.shape)\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
